<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Transforming Data :: AWS System Manager</title>
    <link>http://localhost:1313/4-transforming/index.html</link>
    <description>Introduction In this lab you will learn about AWS Glue, which is a serverless data integration service that makes it easier to discover, prepare, move, and integrate data from multiple sources for analytics, machine learning (ML), and application development. You can use a crawler to populate the AWS Glue Data Catalog with tables. This is the primary method used by most AWS Glue users. A crawler can crawl multiple data stores in a single run. Upon completion, the crawler creates or updates one or more tables in your Data Catalog. Extract, transform, and load (ETL) jobs that you define in AWS Glue use these Data Catalog tables as sources and targets. The ETL job reads from and writes to the data stores that are specified in the source and target Data Catalog tables.</description>
    <generator>Hugo</generator>
    <language>en</language>
    <atom:link href="http://localhost:1313/4-transforming/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Data Validation and ETL With Glue</title>
      <link>http://localhost:1313/4-transforming/4.1/index.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/4-transforming/4.1/index.html</guid>
      <description>PART A: Create Glue Crawler for initial full load data Navigate to the AWS Glue Console On the AWS Glue menu, under ‘Data Catalog’, select Crawlers. Click Create crawler.&#xA;Enter glue-lab-crawler as the crawler name for initial data load.&#xA;Optionally, enter the description. This should also be descriptive and easily recognized and Click Next.</description>
    </item>
  </channel>
</rss>